{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Get Data"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Stocks: 5\n"]}],"source":["from data_processing.stock_Pre_Processing import stock_Pre_Processing\n","from data_processing.calculate_reward import calculate_reward\n","\n","# Name of 5 Stocks  \n","stocks = [\"khodro\", \"shabendar\", \"shapna\", \"vnaft\", \"zamyad\"]\n","print(f\"Number of Stocks: {len(stocks)}\")\n","\n","# Getting Data\n","start = \"2001-07-10\"\n","end = \"2022-04-29\"\n","\n","for stock in stocks:\n","    # Preprocess data\n","    Hour = stock_Pre_Processing(stock, start, end, \"60m\")\n","    Day = stock_Pre_Processing(stock, start, end, \"1d\")\n","    Week = stock_Pre_Processing(stock, start, end, \"1wk\")\n","    \n","    # Reset indexes\n","    Hour.reset_index(drop=True, inplace=True)\n","    Day.reset_index(drop=True, inplace=True)\n","    Week.reset_index(drop=True, inplace=True)\n","    \n","    # Adding rewards to datasets\n","    Hour = calculate_reward(stock,Hour)\n","    Day = calculate_reward(stock,Day)\n","    Week = calculate_reward(stock,Week)\n","\n","    # Save the datasets\n","    PATH = \"datasets/FA_StockPrices/\"\n","    Hour.to_csv(f\"{PATH}{stock}_hour.csv\", index=False)\n","    Day.to_csv(f\"{PATH}{stock}_day.csv\", index=False)\n","    Week.to_csv(f\"{PATH}{stock}_week.csv\", index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# DQN Model"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing data for vnaft...\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Models for vnaft trained and saved.\n","Processing data for zamyad...\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Models for zamyad trained and saved.\n","Processing data for khodro...\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Models for khodro trained and saved.\n","Processing data for shabendar...\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Models for shabendar trained and saved.\n","Processing data for shapna...\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Models for shapna trained and saved.\n"]}],"source":["from math import sqrt\n","from models.deep_q_trading_model import DeepQTrading\n","from utils.preprocessing import preprocess_data\n","\n","deep_q_trading = DeepQTrading()\n","trained_models = {}\n","for company in ['vnaft', 'zamyad', 'khodro', 'shabendar', 'shapna']:\n","    lstm_model, gru_model, combined_model = deep_q_trading.run(company)\n","    trained_models[company] = {\n","        'lstm_model': lstm_model,\n","        'gru_model': gru_model,\n","        'combined_model': combined_model\n","    }\n","    print(f\"Models for {company} trained and saved.\")"]},{"cell_type":"markdown","metadata":{},"source":["# DQN Evaluation"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing data for vnaft...\n","Evaluation Metrics for vnaft:\n","LSTM Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n","MSE: 0.019439881764461497\n","RMSE: 1.3342859252809447\n","MAE: 0.002225459371712307\n","RoR: -0.45178544521331787\n","Return: -81.65585796558265\n","DD: 41.62935068113243\n","Sharpe Ratio: 1.2347071599236588\n","MAPE: 500.0832003134783\n","GRU Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n","MSE: 0.015432698199611124\n","RMSE: 0.4763787128198188\n","MAE: 0.0003761704273987069\n","RoR: -0.4520902931690216\n","Return: -77.94968812444525\n","DD: 12.562912282972786\n","Sharpe Ratio: 1.172049527013162\n","MAPE: 438.23918244795664\n","Combined Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.03336827660766751\n","RMSE: 0.14278246514473772\n","MAE: 0.0011040715348171633\n","RoR: -0.4504532814025879\n","Return: -67.73157394859194\n","DD: 24.39008132175147\n","Sharpe Ratio: 1.0735262008952908\n","MAPE: 506.0884920317969\n","Processing data for zamyad...\n","Evaluation Metrics for zamyad:\n","LSTM Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n","MSE: 0.01810776096946244\n","RMSE: 1.0209477214454654\n","MAE: 0.00018726659799287758\n","RoR: 0.2069217562675476\n","Return: -5.373727068368581\n","DD: 16.283845105203262\n","Sharpe Ratio: 1.5457475478198515\n","MAPE: 500.6624739217089\n","GRU Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.01098353664231336\n","RMSE: 1.7414768296278684\n","MAE: 0.012268670768531673\n","RoR: 0.20674195885658264\n","Return: 8.44073336667968\n","DD: 32.843478495554095\n","Sharpe Ratio: 1.2097345510650366\n","MAPE: 504.8140882478217\n","Combined Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.024196139397806425\n","RMSE: 0.8294291963662717\n","MAE: 0.0019517374758752158\n","RoR: 0.2066718190908432\n","Return: 45.57160966583004\n","DD: 30.775969362458657\n","Sharpe Ratio: 1.3946025896167202\n","MAPE: 522.3079100702388\n","Processing data for khodro...\n","Evaluation Metrics for khodro:\n","LSTM Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.025397528733305225\n","RMSE: 0.3395184921387493\n","MAE: 0.01051928837065902\n","RoR: -0.5490257143974304\n","Return: 48.800979121022124\n","DD: 38.45109633788871\n","Sharpe Ratio: 1.6307271456092314\n","MAPE: 509.3555930249303\n","GRU Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.013463712179110517\n","RMSE: 0.7255263016231509\n","MAE: 0.013390743040246468\n","RoR: -0.5488388538360596\n","Return: -88.17537320703713\n","DD: 13.867407740800315\n","Sharpe Ratio: 1.321200003817387\n","MAPE: 512.6062783651251\n","Combined Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.02129901538473323\n","RMSE: 1.0808394661468315\n","MAE: 0.013496143087924104\n","RoR: -0.5490837097167969\n","Return: -17.28373815904942\n","DD: 16.01965282607823\n","Sharpe Ratio: 1.2689001010730134\n","MAPE: 454.1794320465738\n","Processing data for shabendar...\n","Evaluation Metrics for shabendar:\n","LSTM Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.007342422636966295\n","RMSE: 1.6998389659781967\n","MAE: 0.005700006683918358\n","RoR: -0.7614400386810303\n","Return: -92.25297114081654\n","DD: 40.821499362221054\n","Sharpe Ratio: 1.293199804181461\n","MAPE: 439.6183510350113\n","GRU Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.01466472585314029\n","RMSE: 1.7809538466363994\n","MAE: 0.0025849834713621684\n","RoR: -0.759181022644043\n","Return: -59.13494022998873\n","DD: 14.157585897448882\n","Sharpe Ratio: 1.4457027440010248\n","MAPE: 402.31168112614927\n","Combined Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.029636695260681526\n","RMSE: 0.9234561982347264\n","MAE: 0.0046002144614507405\n","RoR: -0.7619612812995911\n","Return: 61.06634182725094\n","DD: 3.744160492194884\n","Sharpe Ratio: 1.0302783143603618\n","MAPE: 509.0151323956041\n","Processing data for shapna...\n","Evaluation Metrics for shapna:\n","LSTM Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.009171936991706521\n","RMSE: 0.28127881310423475\n","MAE: 0.0006716049077665826\n","RoR: 0.6472564339637756\n","Return: 8.219978958688401\n","DD: 16.54702273316497\n","Sharpe Ratio: 1.317196291644531\n","MAPE: 428.13756296723164\n","GRU Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n","MSE: 0.0009795633856296818\n","RMSE: 1.0316877587075002\n","MAE: 0.0004717091274410162\n","RoR: 0.6475906372070312\n","Return: -14.893917255714499\n","DD: 7.788867828568373\n","Sharpe Ratio: 1.1700397977943429\n","MAPE: 455.64713718103235\n","Combined Model:\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","MSE: 0.031496497521556276\n","RMSE: 1.3754021450779061\n","MAE: 0.000576704177025067\n","RoR: 0.6476686000823975\n","Return: -37.11867534091971\n","DD: 7.376412659953293\n","Sharpe Ratio: 1.64322852466558\n","MAPE: 407.70152733470337\n"]}],"source":["deep_q_trading = DeepQTrading()\n","for company, models in trained_models.items():\n","    X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test, RoR = deep_q_trading.load_data(company)\n","    initial_investment = 10000  # Assuming an initial investment of $10,000\n","        \n","    print(f\"Evaluation Metrics for {company}:\")\n","    print(\"LSTM Model:\")\n","    lstm_metrics = deep_q_trading.evaluate_model(models['lstm_model'], X_test_scaled, y_test, initial_investment)\n","    deep_q_trading.print_metrics(lstm_metrics)\n","    print(\"GRU Model:\")\n","    gru_metrics = deep_q_trading.evaluate_model(models['gru_model'], X_test_scaled, y_test, initial_investment)\n","    deep_q_trading.print_metrics(gru_metrics)\n","    print(\"Combined Model:\")\n","    combined_metrics = deep_q_trading.evaluate_model(models['combined_model'], X_test_scaled, y_test, initial_investment)\n","    deep_q_trading.print_metrics(combined_metrics)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":2}
